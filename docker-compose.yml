version: '3.8'

# ============================================================
# Israel Public Transit Real-Time Monitoring Platform
# Docker Compose - All Services
# ============================================================

networks:
  transit_net:
    driver: bridge

volumes:
  postgres_data:
  airflow_logs:
  minio_data:
  kafka_data:
  zookeeper_data:
  elasticsearch_data:

services:

  # ─────────────────────────────────────────
  # ZOOKEEPER
  # ─────────────────────────────────────────
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: zookeeper
    networks: [transit_net]
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      retries: 5

  # ─────────────────────────────────────────
  # KAFKA BROKER
  # ─────────────────────────────────────────
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    networks: [transit_net]
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "false"
      KAFKA_LOG_RETENTION_HOURS: 48
      KAFKA_MESSAGE_MAX_BYTES: 5242880
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 15s
      retries: 5

  # ─────────────────────────────────────────
  # KAFKA UI
  # ─────────────────────────────────────────
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    networks: [transit_net]
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: transit-cluster
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181

  # ─────────────────────────────────────────
  # KAFKA TOPIC INITIALIZER
  # ─────────────────────────────────────────
  kafka-init:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka-init
    networks: [transit_net]
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: ["/bin/sh", "-c"]
    command: |
      "
      kafka-topics --create --if-not-exists --bootstrap-server kafka:29092 --partitions 4 --replication-factor 1 --topic bus-positions
      kafka-topics --create --if-not-exists --bootstrap-server kafka:29092 --partitions 4 --replication-factor 1 --topic train-positions
      kafka-topics --create --if-not-exists --bootstrap-server kafka:29092 --partitions 2 --replication-factor 1 --topic trip-updates
      kafka-topics --create --if-not-exists --bootstrap-server kafka:29092 --partitions 2 --replication-factor 1 --topic service-alerts
      kafka-topics --create --if-not-exists --bootstrap-server kafka:29092 --partitions 1 --replication-factor 1 --topic delay-events
      kafka-topics --create --if-not-exists --bootstrap-server kafka:29092 --partitions 1 --replication-factor 1 --topic pipeline-errors
      echo 'All transit topics created!'
      "

  # ─────────────────────────────────────────
  # POSTGRESQL - Airflow metadata
  # ─────────────────────────────────────────
  postgres:
    image: postgres:15
    container_name: postgres
    networks: [transit_net]
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 10s
      retries: 5

  # ─────────────────────────────────────────
  # AIRFLOW WEBSERVER
  # ─────────────────────────────────────────
  airflow-webserver:
    image: apache/airflow:2.7.0
    container_name: airflow-webserver
    networks: [transit_net]
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__WEBSERVER__SECRET_KEY: transit_secret_2025
      AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'
      AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      MOT_API_KEY: ${MOT_API_KEY}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      AWS_DEFAULT_REGION: ${AWS_DEFAULT_REGION:-us-east-1}
      S3_BUCKET_NAME: ${S3_BUCKET_NAME:-israel-transit-lake}
      REDSHIFT_HOST: ${REDSHIFT_HOST}
      REDSHIFT_PORT: ${REDSHIFT_PORT:-5439}
      REDSHIFT_DB: ${REDSHIFT_DB:-transit_dw}
      REDSHIFT_USER: ${REDSHIFT_USER}
      REDSHIFT_PASSWORD: ${REDSHIFT_PASSWORD}
      USE_MINIO: ${USE_MINIO:-true}
      MINIO_ENDPOINT: http://minio:9000
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
      - ./producers:/opt/airflow/producers
      - ./consumers:/opt/airflow/consumers
      - ./etl:/opt/airflow/etl
      - ./config:/opt/airflow/config
      - ./storage:/opt/airflow/storage
      - ./warehouse:/opt/airflow/warehouse
    ports:
      - "8081:8080"
    command: webserver
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      retries: 5

  # ─────────────────────────────────────────
  # AIRFLOW SCHEDULER
  # ─────────────────────────────────────────
  airflow-scheduler:
    image: apache/airflow:2.7.0
    container_name: airflow-scheduler
    networks: [transit_net]
    depends_on:
      airflow-webserver:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      MOT_API_KEY: ${MOT_API_KEY}
      AWS_ACCESS_KEY_ID: ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY: ${AWS_SECRET_ACCESS_KEY}
      USE_MINIO: ${USE_MINIO:-true}
      MINIO_ENDPOINT: http://minio:9000
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - airflow_logs:/opt/airflow/logs
      - ./producers:/opt/airflow/producers
      - ./consumers:/opt/airflow/consumers
      - ./etl:/opt/airflow/etl
      - ./config:/opt/airflow/config
      - ./storage:/opt/airflow/storage
      - ./warehouse:/opt/airflow/warehouse
    command: scheduler

  # ─────────────────────────────────────────
  # MINIO - Local S3
  # ─────────────────────────────────────────
  minio:
    image: minio/minio:latest
    container_name: minio
    networks: [transit_net]
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
    volumes:
      - minio_data:/data
    command: server /data --console-address ":9001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 30s
      retries: 3

  # ─────────────────────────────────────────
  # ELASTICSEARCH
  # ─────────────────────────────────────────
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.8.0
    container_name: elasticsearch
    networks: [transit_net]
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health | grep -q 'green\\|yellow'"]
      interval: 20s
      retries: 5

  # ─────────────────────────────────────────
  # KIBANA - Live Dashboard
  # ─────────────────────────────────────────
  kibana:
    image: docker.elastic.co/kibana/kibana:8.8.0
    container_name: kibana
    networks: [transit_net]
    depends_on:
      elasticsearch:
        condition: service_healthy
    ports:
      - "5601:5601"
    environment:
      ELASTICSEARCH_HOSTS: http://elasticsearch:9200